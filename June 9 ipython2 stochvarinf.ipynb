{
 "metadata": {
  "name": "",
  "signature": "sha256:33fef68d6f8423b38d3f273c338d9ee6ece4c98f15d0c4cea0f2018bf4e6d86b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Stochastic variational inference on mixture of Gaussians#"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"https://github.com/caugusta/variational-inference/raw/master/GaussianMixturePlate.png\" alt=\"Plate model of a simplified Gaussian mixture model\" style=\"width:500px\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To simplify things, we assume the variance of $x_i$ is known, and we assume that the mixing proportions are known. We also assume that $\\mu_k$ is governed by $\\omega$, that is $\\mu \\sim G(0, \\omega^2)$. Also, per the usual Gaussian mixture model assumption, we say that each $x_i$ was generated by one and only one of the four Gaussian components in the model (so $x_i \\sim G(\\mu_{z_i}, \\sigma^2)$). Finally, we say $z_i \\sim Cat(\\pi)$. This model is used in Blei's 2014 lecture, [available here](http://www.cs.columbia.edu/~blei/fogm/lectures/mcmc.pdf)\n",
      "\n",
      "We still need to infer the cluster means (global hidden variables $\\mu_k$, with variational parameter $\\lambda_k$) and cluster assignments (local hidden variables $z_i$, with variational parameter $\\phi_i$). \n",
      "\n",
      "<!--\n",
      "NOTE! DO I NEED MORE THAN ONE VARIATIONAL PARAMETER FOR MU?\n",
      "-->\n",
      "\n",
      "As before, there are 4 Gaussian clusters. However, here we will be considering univariate Gaussians as a further simplification.\n",
      "\n",
      "To arrive at the algorithm for stochastic variational inference in the case of a univariate Gaussian mixture model, we have to (according to Hoffman et al 2013):\n",
      "\n",
      "1) Specify the model assumptions\n",
      "\n",
      "2) Get the complete conditionals\n",
      "\n",
      "3) Get the mean field variational family\n",
      "\n",
      "4) Get the stochastic variational inference algorithm.\n",
      "\n",
      "Skipping the intermediate steps to save time (I can show you the derivation afterward), the algorithm for stochastic variational inference, in this case, is:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Algorithm ####\n",
      "\n",
      "1. Set $\\pi$, $\\sigma^2$, $\\omega$, initialize $z$\n",
      "\n",
      "2. Initialize $\\lambda$ randomly.\n",
      "\n",
      "3. Set the step size schedule to $\\rho_t = (1 + t)^{-\\kappa}$ ($\\kappa$ will be chosen via cross-validation)\n",
      "\n",
      "4. Repeat\n",
      "\n",
      "a) Sample $x_i$ uniformly from the dataset\n",
      "\n",
      "b) Compute $\\phi_{z_i} = \\pi_{z_i}\\ell(x_i; \\mu_{z_i}, \\sigma^2)$, holding $\\mu$ constant at the value $\\lambda$.\n",
      "\n",
      "c) Compute $\\hat{\\lambda} = \\hat{\\mu_k}$, holding $z_i$ constant at the level $\\phi_{z_i}$, where \n",
      "\n",
      "$$\\hat\\mu_k = \\left(\\frac{\\frac{\\sum_{i=1}^n z_i^{k}}{\\sigma^2}}{\\frac{\\sum_{i=1}^n z_i^{k}}{\\sigma^2} + \\frac{1}{\\omega^2}}\\right) \\frac{\\sum_{i=1}^n z_i^{k} x_i}{\\sum_{i=1}^n z_i^{k}}$$\n",
      "\n",
      "d) Update $\\lambda = (1 - \\rho_t)\\lambda^{(t-1)} + \\rho_t (\\hat{\\lambda})$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymc as pm\n",
      "import numpy as np\n",
      "from pymc import Dirichlet\n",
      "from pymc import Categorical\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "#Declare the number of observations we have, and the number of clusters\n",
      "ndata = 200\n",
      "k = 4\n",
      "\n",
      "#Initialize pi, sigma^2, omega^2, and z=assts\n",
      "pik = pm.Dirichlet('pik', theta=(1,)*k)\n",
      "pik1 = [pik.random() for i in range(ndata)]\n",
      "zi = pm.Categorical('category', p=pik, size=ndata) #used pymc for this because numpy only has multinomial, no categorical.\n",
      "assts = zi.random()\n",
      "\n",
      "sigma2 = np.matrix([[1, 0.2],[0.2, 1]]) #sigma^2 is a fixed, equal covariance matrix for all clusters.\n",
      "omega2 = np.matrix([[1, 0.01],[0.01, 1]]) #The cluster centres mu are generated from N(0, omega^2). Want well separated.\n",
      "\n",
      "print assts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 3 3 1 1 3 3 0 2 2 0 3 1 0 0 3 0 3 1 1 1 1 0 1 1 0 2 0 1 0 0 0 1 3 1 1 0\n",
        " 1 1 3 1 0 1 3 3 1 1 3 3 1 1 1 3 0 2 3 3 1 0 0 3 3 2 1 3 3 2 1 0 1 1 0 3 3\n",
        " 1 3 3 0 1 1 3 2 0 1 0 2 3 2 1 1 2 3 2 3 2 1 1 3 3 2 0 0 1 2 3 0 3 1 1 0 0\n",
        " 1 1 1 3 0 1 3 1 1 1 1 0 2 0 3 1 0 3 0 1 0 3 1 1 1 3 0 1 1 1 3 1 3 0 0 0 3\n",
        " 1 0 3 0 3 1 3 3 0 2 3 1 1 1 0 3 3 0 2 1 3 1 1 3 3 3 3 3 0 0 1 3 3 0 3 1 3\n",
        " 0 3 1 1 3 1 1 3 3 0 1 3 1 0 0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get the cluster centres\n",
      "mu = np.random.multivariate_normal([0,0], omega2, size=4)\n",
      "print mu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.98359477  2.43008251]\n",
        " [-0.44691866 -0.27878143]\n",
        " [ 0.03901484  1.65476962]\n",
        " [-0.41631194 -0.91314818]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#Generate the data for each cluster\n",
      "#http://www.bayespy.org/examples/gmm.html\n",
      "\n",
      "x0 = np.random.multivariate_normal(mu[0], sigma2, size=ndata/k)\n",
      "x1 = np.random.multivariate_normal(mu[1], sigma2, size=ndata/k)\n",
      "x2 = np.random.multivariate_normal(mu[2], sigma2, size=ndata/k)\n",
      "x3 = np.random.multivariate_normal(mu[3], sigma2, size=ndata/k)\n",
      "\n",
      "obs = np.vstack([x0, x1, x2, x3])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #Initialize lambda randomly (there will be 4 lambdas since there are 4 means, since there are 4 clusters)\n",
      "\n",
      "# #Recall lambda comes from the same distribution as the complete conditional for mu\n",
      "\n",
      "# #We'll need the number of instances of each category/cluster from z\n",
      "# #And we need to calculate the mean and variance of the complete conditional distribution for mu_k\n",
      "# # Note the complete conditional is mu_k ~ MVN(hat_mu_k, hat_omega_k)\n",
      "\n",
      "def sums_a(assts):\n",
      "    # We'll need the number of instances of each category/cluster from z\n",
      "    sums_a = [np.array([np.where(assts==i)]) for i in range(k)]\n",
      "    sums2 = [sums_a[i].size for i in range(k)]\n",
      "    return sums2\n",
      "\n",
      "def hat_mu_k(assts=assts, sigma2=sigma2, omega2=omega2):\n",
      "    \n",
      "    s0 = sums_a(assts)\n",
      "    \n",
      "    # And we need to calculate the mean and variance of the complete conditional distribution for mu_k\n",
      "    # Note the complete conditional is mu_k ~ MVN(hat_mu_k, hat_omega_k)\n",
      "\n",
      "    num = [s0[i]/sigma2 for i in range(k)]\n",
      "    denom = [s0[i]/sigma2 + 1/omega2 for i in range(k)]\n",
      "\n",
      "    s1 = np.array([np.array([sum(obs[0:49])/(ndata/k)]), \n",
      "                   np.array([sum(obs[50:99])/(ndata/k)]),\n",
      "                   np.array([sum(obs[100:149])/(ndata/k)]),\n",
      "                   np.array([sum(obs[150:199])/(ndata/k)])])\n",
      "\n",
      "    hat_mu = [num[i]/denom[i]*s1[i].T for i in range(4)]\n",
      "    hat_mu1 = [np.array([hat_mu[i].T[0,0], hat_mu[i].T[0,1]]) for i in range(k)] #because hat_mu was the wrong dimension.\n",
      "    return hat_mu1\n",
      "\n",
      "def hat_omega_k(assts=assts, sigma2=sigma2, omega2=omega2):\n",
      "    s0 = sums_a(assts)\n",
      "    denom = [s0[i]/sigma2 + 1/omega2 for i in range(k)]\n",
      "    hat_omega = [1/denom[i] for i in range(k)]\n",
      "    return hat_omega\n",
      "    \n",
      "    \n",
      "def lambda_init(hat_mu, hat_omega):\n",
      "    lambdainit = [np.random.multivariate_normal(hat_mu[i], hat_omega[i], size=1) for i in range(k)]\n",
      "    return lambdainit\n",
      "\n",
      "#lambda_new = []\n",
      "#hmu1 = hat_mu_k(assts, sigma2, omega2)\n",
      "#hom1 = hat_omega_k(assts, sigma2, omega2)\n",
      "#lambda_new.append(lambda_init(hmu1, hom1))\n",
      "\n",
      "#print lambda_new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Set the step size schedule. Hoffman et al (2013) recommend starting with tau = 1\n",
      "\n",
      "def step_size(t, kappa, tau=1):\n",
      "    rho_t = (t + tau)**(-kappa)\n",
      "    return rho_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Until abs(lambda_{i-1} - lambda_i) < epsilon or abs(phi_{i-1} - phi_{i}) < epsilon\n",
      "\n",
      "kappa = np.arange(0.01, 1.1, 0.1) #kappa will be chosen via cross-validation later.\n",
      "epsilon = [1e-02]*4\n",
      "\n",
      "obs1 = np.arange(ndata)\n",
      "\n",
      "\n",
      "#Initialize lambda\n",
      "\n",
      "lambda_new = []\n",
      "hat_mu_count = hat_mu_k(assts=assts, sigma2=sigma2, omega2=omega2)\n",
      "hat_omega_count = hat_omega_k(assts=assts, sigma2=sigma2, omega2=omega2)\n",
      "lambda_new.append(lambda_init(hat_mu_count, hat_omega_count))\n",
      "\n",
      "phi_k = []\n",
      "\n",
      "#Get the probability that observation j belongs to cluster i, i = 0,1,2,3\n",
      "pik2 = [([pik1[j][0], pik1[j][1], pik1[j][2], (1 - sum(pik1[j]))]) for j in range(ndata)]\n",
      "    \n",
      "#This will be a while loop, but for now I just want to make sure I don't have an infinite loop!\n",
      "for i in range(1, 10): #this is 1, 2\n",
      " \n",
      "    #Sample 1 observation from the dataset\n",
      "    xindex = np.random.choice(obs1, size=1)\n",
      "    xi = obs[xindex]\n",
      "    print 'i is', i\n",
      "    \n",
      "    #Compute the new values of phi, the local variational parameters, \n",
      "    #using the current value of lambda, the global variational parameters. \n",
      "    #There are k phi values.\n",
      "    \n",
      "    #The complete conditional of z (assts) is a categorical distribution, \n",
      "    #with the parameter equal to the likelihood of the sampled datapoint        \n",
      "    #under the k^{th} cluster multiplied by the probability of the cluster (pi)\n",
      "    #Recall the mean of a categorical distribution is the parameter itself\n",
      "\n",
      "    pk = [pm.mv_normal_cov_like(xi, lambda_new[i-1][j], sigma2)*pik2[xindex][j] for j in range(k)]\n",
      "    phi_k.append(pk)\n",
      "    \n",
      "    #Compute the new values of lambda, the global variational parameters\n",
      "    #using the current value of phi, the local variational parameters\n",
      "    #There are k lambda values.\n",
      "    \n",
      "    #The complete conditional of mu (cluster means) is a multivariate Gaussian distribution,\n",
      "    #with the mean equal to mu_k and the covariance matrix equal to omega_k.\n",
      "    #the value phi_k is used in place of z_k, just like in the previous step\n",
      "    #when the value of lambda_k was used in place of mu_k.\n",
      "    #which means instead of calling functions using \"assts\", we call using phi_k.\n",
      "    \n",
      "    hat_mu_count = hat_mu_k(assts=pk, sigma2=sigma2, omega2=omega2)\n",
      "    hat_omega_count = hat_omega_k(assts=pk, sigma2=sigma2, omega2=omega2)\n",
      "    lambda_hat = lambda_init(hat_mu_count, hat_omega_count)\n",
      "    \n",
      "    #This is the update for lambda, according to the step size rho_k\n",
      "    #According to the proposed update from Hoffman et al 2013, wouldn't the steps only ever be diagonal?\n",
      "    #Also, all of the lambda_k values are updated by the same amount, at the same time.\n",
      "    \n",
      "    step1 = step_size(i, kappa[0], tau=1)\n",
      "    rho = np.array([step1]*2)\n",
      "\n",
      "    lnew = [(1-rho)*lambda_new[i-1][j] + rho*lambda_hat[j] for j in range(k)]\n",
      "    lambda_new.append(lnew)\n",
      "    \n",
      "    difflambda = abs(np.array(lnew) - np.array(lambda_new[i-1]))\n",
      "    diffphi = abs(np.array(pk) - np.array(phi_k[i-1]))\n",
      "    print 'difflambda is', difflambda\n",
      "\n",
      "    #if(difflambda < epsilon or diffphi < epsilon)\n",
      "    #if((lnew - lambda_new[i-1] < epsilon) or (pk - phi_k[i-1] < epsilon)):\n",
      "    #    break\n",
      "\n",
      "#obs = pm.Normal('obs', mean, prec, value=data, observed = True)\n",
      "\n",
      "#IS MY ALGORITHM WRONG? DO I NEED TO WAIT FOR PHI TO CONVERGE (YES) BEFORE I UPDATE LAMBDA? \n",
      "#pg 25/45 of StochVarInf. Contradicts earlier algorithm, so I'm not really sure.\n",
      "#But Memoized paper says you need the optimal value of the local variational parameter\n",
      "#before you update the global variational parameter.\n",
      "\n",
      "#They also have almost everything I need (in theory...) to construct this."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "i is 1\n",
        "difflambda is [[[ 2.87904352  2.29387478]]\n",
        "\n",
        " [[ 3.2057091   1.72886134]]\n",
        "\n",
        " [[ 1.04431445  1.22968722]]\n",
        "\n",
        " [[ 3.18024153  2.92594001]]]\n",
        "i is 2\n",
        "difflambda is [[[ 0.78292408  0.01511472]]\n",
        "\n",
        " [[ 0.5599084   0.18702494]]\n",
        "\n",
        " [[ 0.29338339  1.72117332]]\n",
        "\n",
        " [[ 1.57439396  2.01116612]]]\n",
        "i is 3\n",
        "difflambda is [[[ 1.20663808  0.37876286]]\n",
        "\n",
        " [[ 2.95836812  0.25881786]]\n",
        "\n",
        " [[ 0.86561658  1.10081144]]\n",
        "\n",
        " [[ 3.14124625  1.41837987]]]\n",
        "i is 4\n",
        "difflambda is [[[ 0.40889685  0.74904423]]\n",
        "\n",
        " [[ 1.5996132   1.50725132]]\n",
        "\n",
        " [[ 0.80202168  1.68218921]]\n",
        "\n",
        " [[ 2.39537281  3.50500311]]]\n",
        "i is 5\n",
        "difflambda is [[[ 0.63345263  1.72219922]]\n",
        "\n",
        " [[ 0.0272202   0.02255438]]\n",
        "\n",
        " [[ 0.19121843  0.78543277]]\n",
        "\n",
        " [[ 0.55236715  2.05736075]]]\n",
        "i is 6\n",
        "difflambda is [[[ 2.46515607  2.54976647]]\n",
        "\n",
        " [[ 0.13945589  0.16345469]]\n",
        "\n",
        " [[ 1.92215658  1.38005598]]\n",
        "\n",
        " [[ 0.29057506  0.40372716]]]\n",
        "i is 7\n",
        "difflambda is [[[ 0.78271768  0.38409024]]\n",
        "\n",
        " [[ 1.56419409  1.24139274]]\n",
        "\n",
        " [[ 2.22394976  0.96651508]]\n",
        "\n",
        " [[ 0.9747219   0.36385391]]]\n",
        "i is 8\n",
        "difflambda is [[[ 1.24620153  0.18383101]]\n",
        "\n",
        " [[ 1.67291229  2.01066076]]\n",
        "\n",
        " [[ 0.44024728  0.54446975]]\n",
        "\n",
        " [[ 0.32824785  0.26000126]]]\n",
        "i is 9\n",
        "difflambda is [[[ 3.08028354  1.39747466]]\n",
        "\n",
        " [[ 0.37697594  0.51760235]]\n",
        "\n",
        " [[ 0.51302956  0.3102306 ]]\n",
        "\n",
        " [[ 1.60942418  0.178367  ]]]\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://stackoverflow.com/questions/18987697/how-to-model-a-mixture-of-3-normals-in-pymc\n",
      "\n",
      "import pymc as mc\n",
      "import numpy as np\n",
      "from pymc import database, Matplot\n",
      "%matplotlib inline\n",
      "\n",
      "n = 3\n",
      "ndata = 500\n",
      "\n",
      "dd = mc.Dirichlet('dd', theta=(1,)*n)\n",
      "category = mc.Categorical('category', p=dd, size=ndata)\n",
      "\n",
      "precs = mc.Gamma('precs', alpha=0.1, beta=0.1, size=n)\n",
      "means = mc.Normal('means', 0, 0.001, size=n)\n",
      "\n",
      "@mc.deterministic\n",
      "def mean(category=category, means=means):\n",
      "    return means[category]\n",
      "\n",
      "@mc.deterministic\n",
      "def prec(category=category, precs=precs):\n",
      "    return precs[category]\n",
      "\n",
      "v = np.random.randint( 0, n, ndata)\n",
      "data = (v==0)*(50+ np.random.randn(ndata)) \\\n",
      "       + (v==1)*(-50 + np.random.randn(ndata)) \\\n",
      "       + (v==2)*np.random.randn(ndata)\n",
      "obs = mc.Normal('obs', mean, prec, value=data, observed = True)\n",
      "\n",
      "model = mc.Model({'dd': dd,\n",
      "              'category': category,\n",
      "              'precs': precs,\n",
      "              'means': means,\n",
      "              'obs': obs})\n",
      "\n",
      "mcmc = mc.MCMC( model)\n",
      "mcmc.sample(iter = 10000, burn = 5000, thin = 10)\n",
      "#mcmc.db.close()\n",
      "#mcmc.sample( 50000,0 )\n",
      "m1 = mcmc.trace('means').gettrace()[-1,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [----             11%                  ] 1163 of 10000 complete in 0.5 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [--------         21%                  ] 2176 of 10000 complete in 1.0 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [------------     32%                  ] 3252 of 10000 complete in 1.5 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [---------------  41%                  ] 4177 of 10000 complete in 2.0 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------52%                  ] 5269 of 10000 complete in 2.5 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------62%---               ] 6229 of 10000 complete in 3.0 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------71%-------           ] 7166 of 10000 complete in 3.5 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------81%-----------       ] 8181 of 10000 complete in 4.0 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------91%--------------    ] 9177 of 10000 complete in 4.5 sec"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [-----------------100%-----------------] 10000 of 10000 complete in 4.9 sec"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#db = database.pickle.load('bioassay.pickle')\n",
      "#alpha = db.trace('alpha')\n",
      "Matplot.plot(m1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "plot() takes at least 2 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-30-3bad3a3852d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#db = database.pickle.load('bioassay.pickle')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#alpha = db.trace('alpha')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMatplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/caugusta/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pymc/Matplot.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(pymc_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# If others fail, assume that raw data is passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpymc_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: plot() takes at least 2 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 30
    }
   ],
   "metadata": {}
  }
 ]
}