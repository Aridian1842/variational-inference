{
 "metadata": {
  "name": "",
  "signature": "sha256:16e83a9ba7a2ff9818c3265807c3970eaa9baaae84e93e6e3d53564316d3547a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Introduction to Variational and Stochastic Variational Inference\n",
      "\n",
      "This tutorial-style introduction is geared toward researchers with an introductory undergraduate knowledge of statistics and a working knowledge of neural networks in particular. Since I am a statistician, I will gloss over some of the more computer science-related topics. However, I would gladly accept any suggestions for improvement, especially from a computer science/engineering perspective. Please send constructive criticism to caugusta at uoguelph dot ca\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Outline**\n",
      "\n",
      "Motivating variational inference\n",
      "\n",
      "Discussing vanilla variational inference, with examples\n",
      "\n",
      "Extension to stochastic variational inference, with examples\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " --------------------------------------\n",
      "\n",
      " ## Motivating variational inference ##\n",
      "\n",
      "Following the notation from Bishop 1998, suppose we have a neural network composed of hidden units H and visible units V. There will also be model parameters w.\n",
      "\n",
      "![alt text](https://github.com/caugusta/variational-inference/raw/master/NeuralNetImage.png \"A neural network with a visible layer V, hidden layer H and output\")\n",
      "\n",
      " Using the notation from Bishop 1998:\n",
      " We have visible units V, hidden units H, model parameters w.\n",
      " The model is defined by the distribution P(H, V|w), that is, \n",
      " the joint distribution of the hidden and visible units given the model parameters.\n",
      "\n",
      " The likelihood of the data given a particular setting of the model parameters is the probability of seeing a particular configuration\n",
      " of visible units under ANY setting of the hidden units, given specific values of model parameters. So the probability of seeing the data regardless of the setting of the hidden variables is:\n",
      " \n",
      " $$\\sum_H P(H, V \\mid w) = P(V \\mid w)$$\n",
      " \n",
      "  This process of summing over unwanted variables is called marginalization. If the variables were instead continuous, this would be an integration instead of a sum.\n",
      " \n",
      " \n",
      " We use the joint distribution and the likelihood to construct the posterior distribution:\n",
      " \n",
      " $$P(H \\mid V, w) = \\frac{P(H, V \\mid w)}{P(V \\mid w)}$$\n",
      " \n",
      " That is, the probability of a particular setting of the hidden units, given fixed visible units and model parameters,\n",
      " is the joint probability of the hidden and visible units given the model parameters, divided by the probability that \n",
      " we see a particular setting of the visible units given the model parameters.\n",
      " A simpler version of the previous equation is P(B|A) = P(B, A)/P(A), which is exactly the formula for conditional probability, \n",
      " as seen in many second-year statistics courses.\n",
      " \n",
      " \n",
      " In a lot of practical problems, the posterior distribution is intractable (the sum over all H has too many terms in it - it's computationally infeasible), but we still need to make inferences based on the posterior. If we want to know, for example, the expected value of a particular hidden variable, we have to marginalize over the others in the posterior. One solution involves sampling from the posterior in a Markov chain Monte Carlo (MCMC) approach. However, often MCMC doesn't scale well to high-dimensional problems. Another solution is given by variational methods, which approximate the intractable posterior distribution using a known function. \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " **References**: \n",
      " \n",
      " Bishop, C. Pattern Recognition and Machine Learning. Springer, 2006 (Chapter 10)\n",
      " \n",
      " Hoffman, M. D. et al. Stochastic Variational Inference. Journal of Machine Learning Research, vol. 14. (2013), pp 1303-1347.\n",
      " \n",
      " Bishop, C. Variational Learning in Graphical Models and Neural Networks. 1998\n",
      " \n",
      " Mnih, A. and Gregor, K. Neural Variational Inference and Learning in Belief Networks. 31st ICML, 2014; JMLR vol 32.\n",
      " \n",
      " Volz, E. and Meyers L.A. Epidemic thresholds in dynamic contact networks. J.R. Soc. Interface (2009) vol 6, 233-241.\n",
      " \n",
      " Murphy, K.P. Machine Learning: A Proabilistic Perspective. MIT Press, 2012."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Mean-field variational inference ###\n",
      "\n",
      "In statistical physics, mean field theory has long been used to model complex systems using relatively simple ones. A huge assumption is made, though, that the hidden units $H_1, H_2, ..., H_n$ are independent. This assumption is often false, which leads to alternate methods of variational inference, but it illustrates some nice properties, so that's where we'll start.\n",
      "\n",
      "Say we want to approximate the intractable posterior distribution $P(H \\mid V, w)$\n",
      "\n",
      "We can do so using a function $Q$ that is 'close' to the posterior according to some distance metric.\n",
      "\n",
      "That distance metric is based on maximizing the log-likelihood of the data, ${\\rm{ln}}\\ P(V \\mid w)$. Remember log-likelihood is the log probability of the data we see (the visible units V), given the model parameter settings we have.\n",
      "\n",
      "The log-likelihood can be broken down in the following way (Bishop, 1998):\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\\begin{align}\n",
      "{\\rm{ln}}\\ P(V \\mid w) &= {\\rm{ln}} \\sum_H P(H, V \\mid w) \\\\\n",
      "&= {\\rm{ln}} \\sum_H Q(H \\mid V) \\frac{P(H, V \\mid w)}{Q(H \\mid V)} \\\\\n",
      "&= {\\rm{ln}}\\ E_Q \\left[ \\frac{P(H, V \\mid w)}{Q(H \\mid V)} \\right] {\\rm{\\, since\\ E_X(g(X)) = \\sum_x g(x)f(x),\\ by\\ definition\\ of\\ expectation,\\ taking\\ the\\ expectation\\ with\\ respect\\ to\\ Q(H \\mid V)}}\\\\\n",
      "&\\ge E_Q\\ {\\rm{ln}} \\left[ \\frac{P(H, V \\mid w)}{Q(H \\mid V)}\\right] {\\rm{\\, by\\ Jensen's\\ Inequality}} \\\\\n",
      "&= {\\rm{L}}(Q, w) \\\\\n",
      "\\end{align}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\\begin{align}\n",
        "{\\rm{ln}}\\ P(V \\mid w) &= {\\rm{ln}} \\sum_H P(H, V \\mid w) \\\\\n",
        "&= {\\rm{ln}} \\sum_H Q(H \\mid V) \\frac{P(H, V \\mid w)}{Q(H \\mid V)} \\\\\n",
        "&= {\\rm{ln}}\\ E_Q \\left[ \\frac{P(H, V \\mid w)}{Q(H \\mid V)} \\right] {\\rm{\\, since\\ E_X(g(X)) = \\sum_x g(x)f(x),\\ by\\ definition\\ of\\ expectation,\\ taking\\ the\\ expectation\\ with\\ respect\\ to\\ Q(H \\mid V)}}\\\\\n",
        "&\\ge E_Q\\ {\\rm{ln}} \\left[ \\frac{P(H, V \\mid w)}{Q(H \\mid V)}\\right] {\\rm{\\, by\\ Jensen's\\ Inequality}} \\\\\n",
        "&= {\\rm{L}}(Q, w) \\\\\n",
        "\\end{align}"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x101f95350>"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aside: Jensen's Inequality applied here is ${\\rm{ln}}(E(X)) \\ge E({\\rm{ln}} (X))$, and more information is available [here](http://en.wikipedia.org/wiki/Jensen's_inequality). The vast majority of this derivation is given in Bishop (1998)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we have a lower bound on the log probability of the visible units. We want to choose $Q(H \\mid V)$ such that this lower bound is as close to the true log probability as possible. Bishop (1998) goes on to say that the KL divergence between $Q$ and $P$, given by\n",
      "\n",
      "$${\\rm{KL}}(Q \\mid P) = -\\sum_H Q(H \\mid V)\\ {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)}{Q(H \\mid V)}\\right]$$\n",
      "\n",
      "is the difference between the true log likelihood and the lower bound. I didn't believe that, so by building up from Bishop (2006) (Chapter 10) and Murphy (2012) (Chapter 21), here is the proof:\n",
      "\n",
      "Claim: ${\\rm{ln}}\\ P(V \\mid W) = {\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P)$\n",
      "\n",
      "Proof:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\n",
      "\\begin{align}\n",
      "{\\rm{L}}(Q, w) &= \\sum_H Q(H \\mid V) {\\rm{ln}} \\left[\\frac{P(H, V \\mid w)}{Q(H \\mid V)}\\right] \\\\[0.5em]\n",
      "&= \\sum_H Q(H \\mid V) {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)P(V \\mid w)}{Q(H \\mid V)}\\right] {\\rm{,\\ again\\ due\\ to\\ conditional\\ probability}}\\\\[0.5em]\n",
      "&= \\sum_H Q(H \\mid V) \\left[{\\rm{ln}}\\ P(H \\mid V, w) + {\\rm{ln}}\\ P(V \\mid w) - {\\rm{ln}}\\ {Q(H \\mid V)}\\right] \\\\[0.5em]\n",
      "\\end{align}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\n",
        "\\begin{align}\n",
        "{\\rm{L}}(Q, w) &= \\sum_H Q(H \\mid V) {\\rm{ln}} \\left[\\frac{P(H, V \\mid w)}{Q(H \\mid V)}\\right] \\\\[0.5em]\n",
        "&= \\sum_H Q(H \\mid V) {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)P(V \\mid w)}{Q(H \\mid V)}\\right] {\\rm{,\\ again\\ due\\ to\\ conditional\\ probability}}\\\\[0.5em]\n",
        "&= \\sum_H Q(H \\mid V) \\left[{\\rm{ln}}\\ P(H \\mid V, w) + {\\rm{ln}}\\ P(V \\mid w) - {\\rm{ln}}\\ {Q(H \\mid V)}\\right] \\\\[0.5em]\n",
        "\\end{align}"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x101f959d0>"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall the definition of the KL divergence:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$${\\rm{KL}}(Q \\mid P) = -\\sum_H Q(H \\mid V)\\ {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)}{Q(H \\mid V)}\\right]$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\n",
      "\\begin{align}\n",
      "{\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P) &= \\sum_H Q(H \\mid V) \\left[{\\rm{ln\\ }} P(H \\mid V, w) + {\\rm{ln\\ }} P(V \\mid w) - {\\rm{ln\\ }} {Q(H \\mid V)}\\right] - \\sum_H Q(H \\mid V)\\ {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)}{Q(H \\mid V)}\\right] \\\\[0.5em] \n",
      "&=\\sum_H Q(H \\mid V) \\left[{\\rm{ln\\ }} P(H \\mid V, w) + {\\rm{ln\\ }} P(V \\mid w) - {\\rm{ln\\ }} {Q(H \\mid V)}\\right] - \\sum_H Q(H \\mid V)\\ {\\rm{ln\\ }} P(H \\mid V, w) + \\sum_H {Q(H \\mid V)} {\\rm{ln\\ }} Q(H \\mid V) \\\\[0.5em]\n",
      "&=\\sum_H Q(H \\mid V){\\rm{ln}}\\ P(H \\mid V, w) + \\sum_H Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w) - \\sum_H Q(H \\mid V){\\rm{ln\\ }} {Q(H \\mid V)} - \\sum_H Q(H \\mid V)\\ {\\rm{ln\\ }} P(H \\mid V, w) + \\sum_H {Q(H \\mid V)} {\\rm{ln\\ }} Q(H \\mid V) \\\\[0.5em]\n",
      "&={\\sum_H  Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w)}\n",
      "\\end{align}\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\n",
        "\\begin{align}\n",
        "{\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P) &= \\sum_H Q(H \\mid V) \\left[{\\rm{ln\\ }} P(H \\mid V, w) + {\\rm{ln\\ }} P(V \\mid w) - {\\rm{ln\\ }} {Q(H \\mid V)}\\right] - \\sum_H Q(H \\mid V)\\ {\\rm{ln}} \\left[\\frac{P(H \\mid V, w)}{Q(H \\mid V)}\\right] \\\\[0.5em] \n",
        "&=\\sum_H Q(H \\mid V) \\left[{\\rm{ln\\ }} P(H \\mid V, w) + {\\rm{ln\\ }} P(V \\mid w) - {\\rm{ln\\ }} {Q(H \\mid V)}\\right] - \\sum_H Q(H \\mid V)\\ {\\rm{ln\\ }} P(H \\mid V, w) + \\sum_H {Q(H \\mid V)} {\\rm{ln\\ }} Q(H \\mid V) \\\\[0.5em]\n",
        "&=\\sum_H Q(H \\mid V){\\rm{ln}}\\ P(H \\mid V, w) + \\sum_H Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w) - \\sum_H Q(H \\mid V){\\rm{ln\\ }} {Q(H \\mid V)} - \\sum_H Q(H \\mid V)\\ {\\rm{ln\\ }} P(H \\mid V, w) + \\sum_H {Q(H \\mid V)} {\\rm{ln\\ }} Q(H \\mid V) \\\\[0.5em]\n",
        "&={\\sum_H  Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w)}\n",
        "\\end{align}"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x101f934d0>"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall $Q(H \\mid V)$ is a probability mass function, so $\\sum\\limits_H Q(H \\mid V) = 1$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "\n",
      "\\begin{align}\n",
      "{\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P) &= {\\sum_H  Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w)} \\\\\n",
      "&= {\\rm{ln}}\\ P(V \\mid w) \\sum_H  Q(H \\mid V) {\\rm{\\ , Since\\ ln\\ }} P(V \\mid w) {\\rm{\\ has\\ no\\ H}} \\\\\n",
      "&= {\\rm{ln}}\\ P(V \\mid w)\n",
      "\\end{align}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\n",
        "\\begin{align}\n",
        "{\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P) &= {\\sum_H  Q(H \\mid V){\\rm{ln}}\\ P(V \\mid w)} \\\\\n",
        "&= {\\rm{ln}}\\ P(V \\mid w) \\sum_H  Q(H \\mid V) {\\rm{\\ , Since\\ ln\\ }} P(V \\mid w) {\\rm{\\ has\\ no\\ H}} \\\\\n",
        "&= {\\rm{ln}}\\ P(V \\mid w)\n",
        "\\end{align}"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x101f953d0>"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore ${\\rm{ln}}\\ P(V \\mid W) = {\\rm{L}}(Q, w) + {\\rm{KL}}(Q \\mid P)$, as desired."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Building up stochastic variational inference from vanilla variational inference\n",
      "Start from Bishop 1998.\n",
      "Add from Bishop 2006, with my proofs.\n",
      "Add from Hoffman et al 2013, applied to Bishop 1998 examples, and compared with vanilla variational inference.\n",
      "How can Neural Variational Inference be added to this?\n",
      "Apply to a dynamic model, structured similarly to Epidemic Thresholds on Dynamic Contact Networks work."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}