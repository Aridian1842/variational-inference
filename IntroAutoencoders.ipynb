{
 "metadata": {
  "name": "",
  "signature": "sha256:61703653f786e71229dd10576d8686a15b11484967faa127b87cc6e15fa660c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Introduction to Autoencoders#\n",
      "\n",
      "Autoencoders (or autoassociators) are a class of feedforward neural network that learns to model the input $x$ with as little distortion as possible (Baldi, 2012). A traditional autoencoder consists of an input layer, a hidden layer, and an output layer, with directed connnections from input to hidden and from hidden to output (Figure 1). Deep autoencoders have more hidden layers, but retain a symmetric structure (Michl, 2013).\n",
      "\n",
      "While this sounds a lot like a multilayer perceptron (MLP), an autoencoder has the same number of output units as input units, whereas an MLP has fewer output units. The point of an autoencoder is to reconstruct the input as faithfully as possible, whereas a multilayer perceptron is used, for example, for classification (so the output layer would have k nodes, where k is the number of classes, and typically k << n, where n is the number of inputs $x$). Autoencoders are used for unsupervised learning tasks such as feature extraction, generating more unlabelled data that closely resembles the original data, and as a starter for a subsequent classification network. Another important aspect to autoencoders is that their learning paradigm is entirely unsupervised: that is, there is no target (per se - you could also say the input is the target).  \n",
      "\n",
      "<img src=\"https://github.com/caugusta/variational-inference/raw/master/AutoEncoder1.png\" alt=\"\" style=\"width:300px\">\n",
      "\n",
      "<!--\n",
      "![alt text](https://github.com/caugusta/variational-inference/raw/master/AutoEncoderBaldi2012.png \"A typical autoencoder, with n inputs, p hidden units, and n outputs\"{width=100px)\n",
      "-->\n",
      "\n",
      "\n",
      "Here, the input layer is denoted $x$, the hidden layer $h$, and the output layer $\\bar{x}$. The weights from the input layer to the hidden layer are often called the recognition weights. The weights from the hidden layer to the output are the generative weights (Hinton and Zemel, 1994). We often choose to tie the weights (that is, we choose the generative weights to be equal to the recognition weights, transposed). The dimensionality $p$ of the hidden layer is a parameter to be tuned during learning. Included in the weight matrix is a vector for the bias on each neuron. Much of the notation in this iPython notebook follows Hugo Larochelle's lecture videos. \n",
      "\n",
      "<!-- \n",
      "Is there a connection between autoencoders and bootstrapping? They can accomplish the same goals, so are they in any way mathematically similar?\n",
      "-->"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<!--\n",
      "The transformation from input to hidden units is denoted B, and the transformation from hidden to output is A. The transformation B is a weight matrix that takes the input layer and multiplies each input node by a constant. \n",
      "\n",
      "\n",
      "We often choose to tie the weights, although we don't have to. That is, we often make the weights from the input layer (often called the recognition weights) to the hidden layer equal to the weights from the hidden layer to the output layer (but transposed, of course - these are called the generative weights) (Hinton and Zemel, 1994).\n",
      "\n",
      "-->\n",
      "\n",
      "An autoencoder consists of an encoder, a function taking the data and learning a representation of the input, and a decoder, which maps from the representation back to the input.\n",
      "\n",
      "\n",
      "An autoencoder consists of two main parts: an encoder and a decoder. The encoder is a mapping from input units to hidden units; the decoder goes from hidden units to \"output\" units. The encoder function is often a sigmoid nonlinearity; that is:\n",
      "\n",
      "$$h = \\frac{1}{1 + {\\rm{exp}}(-(Wx))}$$\n",
      "\n",
      "...or a linear function (which is just an identity mapping):\n",
      "\n",
      "$$h = Wx$$\n",
      "\n",
      "where $W$ is the matrix of recognition weights, and $x$ is a $d$-dimensional input vector. \n",
      "\n",
      "The decoder function is also a either sigmoid (when we use binary units - more on this later):\n",
      "\n",
      "$$\\bar{x} = \\frac{1}{1 + {\\rm{exp}}(-( W^{T}h))}$$\n",
      "\n",
      "...or a linear function:\n",
      "\n",
      "$$\\bar{x} = W^{T}h $$\n",
      "\n",
      "where $W^{T}$ is the matrix of generative weights connecting the input layer and the output layer. \n",
      "\n",
      "## The loss function (reconstruction error) ##\n",
      "\n",
      "The loss function for learning autoencoders is a function of the difference between the output $\\hat{x}$ and the input $x$. This reconstruction loss function can take one of several forms depending on the type of data under consideration. \n",
      "\n",
      "### Binary input units ###\n",
      "\n",
      "If the input $x$ are binary units, and we have a sigmoid activation function in the decoder (going from the hidden to the output), we use the cross-entropy error function:\n",
      "\n",
      "$$f(x) = - \\sum_{k=1}^{n}\\ (\\ x_k {\\rm{\\log}}(\\bar{x}_k) + (1 - x_k){\\rm{log}}(1 - \\bar{x}_k)\\ )$$\n",
      "\n",
      "Recall the definition of entropy between two distributions (suppose $X$ is a random variable with realizations $x$, and $P(X = x)$ and $Q(X = x)$: \n",
      "\n",
      "$$- \\sum_{x \\in X} P(X = x) {\\ \\rm{log}}\\ Q(X = x)$$ \n",
      "\n",
      "If $X \\in \\left\\{0, 1\\right\\}$, then this is a sum over the probability that $X = 0$ and that $X = 1$, so this becomes:\n",
      "\n",
      "$$- \\left[P(X = 1)\\ {\\rm{log}\\ } Q(X = 1) + P(X = 0)\\ {\\rm{log}\\ } Q(X = 0)\\right]$$\n",
      "\n",
      "Now if we follow the autoencoder framework, $P(X = 1)$ is our $x_k$, and $Q(x = 1)$ is our $\\bar{x}_k$, and $P(X = 0) = 1 - x_k$, $Q(X = 0) = 1 - \\bar{x}_k$. Considering all data points $x_k$, we arrive at:\n",
      "\n",
      "$$ - \\sum_{k=1}^{n} \\ (\\ x_k {\\rm{\\log}}(\\bar{x}_k) + (1 - x_k){\\rm{log}}(1 - \\bar{x}_k)\\ )$$\n",
      "\n",
      "This error function makes a lot of sense for binary units. To illustrate this, suppose for the moment we're only interested in one unit, $x_k$. If the true value of $x_k$ is 1, then the second term is 0 and the first term becomes $- {\\rm{log}} (\\bar{x_k})$. Since we want to minimize reconstruction error, we want to minimize $- {\\rm{log}} (\\bar{x_k})$. By duality, this is the same as maximizing $ {\\rm{log}} (\\bar{x_k})$. So we're pushing the log of the output to be as close as possible to 1. \n",
      "\n",
      "If the true value of $x_k$ is 0, then the first term is 0 and the second term becomes $ - {\\rm{log}} (1 - \\bar{x}_k)$. Using the same reasoning as above, we're maximizing ${\\rm{log}}(1 - \\bar{x}_k)$, trying to push $\\bar{x}_k$ to 0 to match the input $x_k$.\n",
      "\n",
      "\n",
      "### Real-valued input units ###\n",
      "\n",
      "If the input $x$ are real-valued, it's common to use squared error loss (Euclidean distance).\n",
      "\n",
      "$$f(x) = - \\frac{1}{2} \\sum_{k=1}^{n}\\ (\\bar{x}_k - x_k)^2$$\n",
      "\n",
      "Typically we would also have, instead of sigmoid nonlinearities, just plain linear activation functions.\n",
      "\n",
      "Other types of input are also possible, but real and binary are two of the most common loss functions (Larochelle).\n",
      "\n",
      "### How learning works ###\n",
      "\n",
      "To get to how to learn an autoencoder, we need a quick refresher on the functions that are used in the autoencoder.\n",
      "\n",
      "There's a hidden layer pre-activation function that takes the input layer and multiplies it by the recognition weights:\n",
      "\n",
      "$$ a(x) = Wx $$\n",
      "\n",
      "There's a hidden layer activation function that transforms a(x) (this is the encoder):\n",
      "\n",
      "$$ h = g(a(x))$$\n",
      "\n",
      "There's an output layer pre-activation function that multiplies h by the generative weights:\n",
      "\n",
      "$$ \\hat{a}(x) = W^{T}h $$\n",
      "\n",
      "And there's an output layer activation function that transforms $\\hat{a}(x)$ (this is the decoder):\n",
      "\n",
      "$$ \\bar{x} = m(\\hat{a}(x)) $$\n",
      "\n",
      "Learning, as usual, is conducted via gradient descent. Whether we use a cross-entopy error function or a squared error function for the reconstruction loss, the gradient of the pre-activation of the decoder (that is, the gradient of $\\hat{a}(x)$) with respect to the loss is the same:\n",
      "\n",
      "$$\\nabla_{\\hat{a}(x_k)} = \\bar{x}_k - x_k$$ \n",
      "\n",
      "From this point, we can use the backpropagation algorithm to get the gradients with respect to the parameters. One important point is that if we choose to use tied weights as shown here, the gradient with respect to the weight matrix W will be a sum of the gradient given in W^\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "<!--\n",
      "### Common traditional autoencoders ###\n",
      "\n",
      "#### Linear autoencoders ####\n",
      "\n",
      "Suppose we have real-valued input $x$. If $m$ and $a$ are linear functions (identity mappings) we get a linear autoencoder. Of course, since this would just yield a sequence of linear transformations, this can be compressed into just one The sigmoid function that we usually use may not be necessary, or even useful, in some cases.\n",
      "\n",
      "Relationship between Principal Components Analysis (PCA) and linear autoencoders\n",
      "\n",
      "Interestingly, if we use a squared error loss term and a linear decoder, the optimal hidden layer (in terms of reconstruction error) is given by a linear transformation.\n",
      "-->"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Denoising autoencoders ###\n",
      "\n",
      "A traditional autoencoder learns the best set of hidden units that minimize the reconstruction loss, and has fewer hidden nodes than inputs. The point of this classic autoencoder is to learn a more compact representation of the data. The problem with more compact descriptions is that there's less room for error. That is, autoencoders with fewer hidden nodes than input nodes are not robust to the presence of noise in the data. \n",
      "\n",
      "To make the system more robust to noise, we need an overcomplete representation. That is, we need more hidden units than input units. At first glance, this seems like a bad idea. The hidden layer could simply learn the identity function, and reconstruct the inputs exactly, instead of learning a useful representation. Of course this is true, but once noise is injected, a simple copy would not be a faithful representation of the true input. This is best seen through an image:\n",
      "\n",
      "<img src=\"https://github.com/caugusta/variational-inference/raw/master/AutoEncoder.png\" alt=\"\" style=\"width:300px\">\n",
      "\n",
      "We now have four layers: \n",
      "\n",
      "1) A non-noisy input layer $x$\n",
      "2) Input with injected noise $\\tilde{x}$\n",
      "3) A hidden layer h($\\tilde{x})\n",
      "4) An output layer $\\bar{x}$\n",
      "\n",
      "One way to inject noise is to randomly remove some of the input elements (that is, replace their values with zeros). Since the noisy input layer is connected to the hidden layer, and the original input is not, learning the identity function would not be helpful for reconstructing the true input (because then the hidden units connecting to the noisy $\\tilde{x}$ would only ever be 0). Another way to include noise is to add Gaussian noise, with mean 0 and some covariance matrix, to the original data. The covariance matrix would then be a hyperparameter to be optimized.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Contractive autoencoders ###\n",
      "\n",
      "Another common extension to classical autoencoders is the so-called contractive autoencoder. Instead of injecting noise in the system, this autoencoder (with an overcomplete representation) will penalize the identity as a solution. The goal is to construct a system that will only extract features that reflect variations in the training set. All other variability should be penalized. This necessitates another term in the loss function:\n",
      "\n",
      "new loss function = reconstruction error + hyperparameter*(Jacobian of the encoder)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sparse autoencoders (Ng, ### MORNING: Incoporate Ng sparse autoencoders and that thesis.\n",
      "\n",
      "To wrap up the discussion on non-deep autoencoders, a variant called a sparse autoencoder has also generated interest recently. In a sparse autoencoder, an overcomplete representation is also used, but sparsity is enforced. The knee-jerk reaction here is to dismiss the structure as being the same as a typical undercomplete autoencoder (where the number of hidden units is less than the number of input units). However, the loss function is slightly different. \n",
      "\n",
      "Here, we want to enforce the constraint that the activation of all hidden units is equal to the average activation (which we restrict to be close to 0). So on average, very few hidden units are active at any given time. This sparsity constraint forces all hidden units to learn useful features, so that even when only a few are being used to reconstruct the input, they can still get a pretty good guess at what the input should look like.\n",
      "\n",
      "Using notation from Ng (2011), suppose "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Stacked autoencoders ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### References ###\n",
      "\n",
      "Hinton, G. E. and Zemel, R. S. (1994). Autoencoders, minimum description length, and Helmholtz free energy. Advances in Neural Information Processing Systems 6. J. D. Cowan, G. Tesauro and J. Alspector (Eds.), Morgan Kaufmann: San Mateo, CA.\n",
      "\n",
      "Ng, Andrew (2011). Sparse Autoencoder. CS294A Lecture Notes. Stanford University. [Online](https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf)\n",
      "\n",
      "Michl, P. (2013) Structure learning with deep autoencoders. Network Modeling Seminar. Universitat Heidelberg. [Online](https://www.mathi.uni-heidelberg.de/~pmichl/files/talks/Network%20modeling%20seminar%20-%20Structure%20learning%20with%20deep%20autoencoders.pdf)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}